{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c624b19",
   "metadata": {},
   "source": [
    "# Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f2c5a",
   "metadata": {},
   "source": [
    "### Contribution\n",
    "- New state of the art for image SR with high upscaling factors (4×) \n",
    "- We propose SRGAN which is a GAN-based network optimized for a new perceptual loss.(VGG network)\n",
    "- We conﬁrm with an extensive mean opinion score (MOS) test. SRGAN is the new state of the art"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c67d2c",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*6VPZ5mLkO_2j6D3rYs08rg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721947a2",
   "metadata": {},
   "source": [
    "### Method\n",
    "- In training, $I^{LR}$is obtained by applying a Gaussian ﬁlter to $I^{HR}$ followed by a downsampling operation with downsampling factor r. \n",
    "- For an image with C color channels, we describe $I^{LR}$ by a real-valued tensor of size $W \\times H \\times C$ and $I^{HR}$ , $I^{SR}$ by $rW \\times rH \\times C$ respectively. ( 32x32->256 x256 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b98d0",
   "metadata": {},
   "source": [
    "- generator network as a feed-forward CNN $G_{\\theta_G}$ parametrized by $\\theta_G$ where $\\theta_G= \\left\\{ W_{1:L}; b_{1:L}\\right\\}$\n",
    "$$\\hat{\\theta_G} = \\arg\\min_{\\theta_G}\\sum_{n=1}^N{l^{SR}}(G_{\\theta_G}(I_{n}^{LR}), I_{n}^{HR})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a7cfc",
   "metadata": {},
   "source": [
    "#### Adversarial network architecture\n",
    "##### adversarial min-max problem\n",
    "$$\\min_{\\theta_{G}}\\max_{\\theta_{D}} \\mathbb{E}_{I^{HR} \\sim  p_{train}(I^{HR})}[\\log D_{\\theta_D}(I^{HR})] + \\mathbb{E}_{I^{LR} \\sim  p_{G}(I^{LR})}[\\log (1 - D_{\\theta_D}(G_{\\theta_G}(I^{LR}))]$$\n",
    "- real : 1, fake : 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f3591",
   "metadata": {},
   "source": [
    "<img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-19_at_11.13.45_AM_zsF2pa7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda91b6",
   "metadata": {},
   "source": [
    "### Perceptual loss function \n",
    "$$l^{SR} = \\underbrace{\\underbrace{l_{X}^{SR}}_{\\text{content loss}} +  \\underbrace{10^{-3}l_{Gen}^{SR}}_{\\text{adversarial loss}}}_{\\text{perceptual loss (for VGG based content losses)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9b6b2",
   "metadata": {},
   "source": [
    "#### Content loss \n",
    "$$l_{MSE}^{SR}  = \\frac{1}{r^2 {WH}}\\sum_{x=1}^{rW}\\sum_{y=1}^{rH}(I_{x,y}^{HR} - G_{\\theta_{G}}(I^{LR})_{x,y})^2$$\n",
    "$$l_{VGG/i,j}^{SR}  = \\frac{1}{{W_{i,j}H_{i,j}}}\\sum_{x=1}^{W_{i,j}}\\sum_{y=1}^{H_{i,j}}(\\phi_{i,j}(I^{HR})_{x,y} - \\phi_{i,j}(G_{\\theta_{G}}(I^{LR}))_{x,y})^2$$\n",
    "- With $\\phi_{i,j}$we indicate the feature map obtained by the j-th convolution (after activation) before the i-th maxpooling layer within the VGG19 network  \n",
    "- $W_{i,j}, H_{i,j}$ : dimensions of the respective feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a74af20",
   "metadata": {},
   "source": [
    "#### Adversarial loss\n",
    "$$l_{Gen}^{SR} = \\sum_{n=1}^N -\\log(D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2142602",
   "metadata": {},
   "source": [
    "- $D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$ is the probability that the reconstructed image $G_{\\theta_G}(I^{LR})$ is a natural HR image.\n",
    "- For better gradient behavior we minimize $-\\log(D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$ instead of $\\log(1- D_{\\theta_D}(G_{\\theta_G}(I^{LR}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c76ba",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSCIhF%2FbtqxbAJhlqT%2FvTRwkPDy0oDXKEI5rBo09k%2Fimg.png\">\n",
    "\n",
    "- SRGAN-MSE: $l_{MSE}^{SR}$, to investigate the adversarial network with the standard MSE as content loss.\n",
    "- SRGAN-VGG22: $l_{VGG/2,2}^{SR}$ with $\\phi_{2,2}$, a loss deﬁned on feature maps representing lower-level features .\n",
    "- SRGAN-VGG54: $l_{VGG/5,4}^{SR}$ with $\\phi_{5,4}$, a loss deﬁned on feature maps of higher level features from deeper network layers with more potential to focus on the content of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3d331",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*WQfn6Jo2uagFaSP6eQ5jjQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24980603",
   "metadata": {},
   "source": [
    "https://github.com/tensorlayer/srgan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c8447",
   "metadata": {},
   "source": [
    "https://github.com/eriklindernoren/PyTorch-GAN/blob/36d3c77e5ff20ebe0aeefd322326a134a279b93e/implementations/srgan/srgan.py#L66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e8d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
